# A Comprehensive Study in Natural Language Inference with MultiNLI Corpus

## Overview

Welcome to the repository dedicated to Natural Language Inference (NLI), featuring code implementations utilizing DistilBERT, RoBERTa, mBERT, Mistral-7B-v0.1, and TinyLlama-1.1B-Chat-v1.0 on the MultiNLI dataset.

## Dataset

### MultiNLI Dataset
The [MultiNLI Dataset](https://huggingface.co/datasets/multi_nli?row=1) is a comprehensive collection of 433k sentence pairs annotated with textual entailment information. Modeled on the SNLI corpus, MultiNLI covers a range of genres in spoken and written text, offering a distinctive cross-genre generalization evaluation for Natural Language Inference tasks.

## Models

### Pretrained BERTs
Leveraging transformer-based models from Hugging Face Transformers library:
- **DistilBERT**
  - Model Link: [DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert)
- **RoBERTa**
  - Model Link: [RoBERTa](https://huggingface.co/docs/transformers/model_doc/roberta)
- **mBERT**
  - Model Link: [mBERT](https://huggingface.co/bert-base-multilingual-cased)

### Large Language Models (LLMs)
For Natural Language Inference on the MultiNLI dataset, two LLMs have been employed:
- **Mistral-7B-v0.1**
  - Model Link: [Mistral-7B-v0.1](https://huggingface.co/mistralai/Mistral-7B-v0.1)
- **TinyLlama-1.1B-Chat-v1.0**
  - Model Link: [TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)

Feel free to explore the code implementations and experiment with these models for a comprehensive study in Natural Language Inference using the MultiNLI corpus.
